---
title: RUBIX 
tagline: RUBIX
image: /images/safe-rl.png
preview: Fast GPU-
date: 2024-05-20
authors: Ufuk Ã‡akÄ±r
github: https://github.com/AstroAI-Lab/rubix
paper:  https://arxiv.org/abs/2412.08265
---


# ğŸš€ RUBIX â€” GPU-Turbo Forward Modeling for IFU Data Cubes

**Fast, JAX-powered & auto-differentiable**  
[ğŸ“„ Read the paper](https://arxiv.org/abs/2412.08265)

| ğŸ’¡ Why it matters | ğŸ› ï¸ What RUBIX does | âš¡ How fast? |
|:------------------|:-------------------|:------------|
| Bridging the gap between simulations and observations of galaxies | End-to-end pipeline in **JAX** that turns hydro-sim data into realistic IFU cubes | **600Ã—** faster than GalCraft on an NVIDIA A100 |
| Enables gradient-based ML & simulation-based inference | Runs natively on **multiple GPUs** with `pmap` + XLA | From **1.4 h â†’ 8.6 s** for a 6M-particle galaxy |
| Open-source, modular, fully tested | Auto-diff through every step (SSP lookup â†’ Doppler shift â†’ PSF/LSF â†’ noise) | Scales to 8 GPUs (needs tuning for perfect efficiency) |

---

## ğŸ” Key ingredients
- âš¡ **Vectorised kernels** (`vmap`) â€” no slow Python loops
- âš¡ **Just-in-time compilation** â€” XLA fuses ops for extra speed
- âš™ï¸ **JSON-driven configs** â€” choose telescope, SSP library, distance, orientation, and more

---

## ğŸ“ˆ Results in a snapshot
- ğŸ“Š Reproduces expected flux & spectral gradients across galactic radii
- ğŸ“‰ Strong scaling: runtime grows *sub-linearly* with particle number
- ğŸ”Œ Weak scaling: still room to optimise multi-GPU communication

---

## ğŸ›¤ï¸ Coming down the pipe
- ğŸŒ«ï¸ Gas & dust modelling
- ğŸ’¡ Radiative-transfer in pure JAX
- ğŸ”„ End-to-end neural-physics hybrids for SBI & Bayesian model comparison

---

## â­ Take-away
**RUBIX** turns hours of CPU work into **seconds** on GPUs and provides **gradients** for modern ML workflows â€” unlocking rapid, differentiable astrophysics! ğŸš€
